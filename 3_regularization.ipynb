{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (100000, 28, 28) (100000,)\n",
      "Validation set (5000, 28, 28) (5000,)\n",
      "Test set (5000, 28, 28) (5000,)\n",
      "Final Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  final_test_dataset = save['final_test_dataset']\n",
    "  final_test_labels = save['final_test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)\n",
    "  print('Final Test set', final_test_dataset.shape, final_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (100000, 784) (100000, 10)\n",
      "Validation set (5000, 784) (5000, 10)\n",
      "Test set (5000, 784) (5000, 10)\n",
      "Final Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "final_test_dataset, final_test_labels = reformat(final_test_dataset, final_test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "print('Final Test set', final_test_dataset.shape,final_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's introduce L2 regularization in the SGD logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model Without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "\n",
    "def log_reg(x, weights, biases):\n",
    "    '''\n",
    "    x: tf array with the training examples\n",
    "    weights: tensor containing the weights\n",
    "    biases: tensor containing the biases \n",
    "    ''' \n",
    "    return tf.add(tf.matmul(x,weights),biases)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.5\n",
    "num_steps = 3001\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = log_reg(tf_train_dataset, weights, biases)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 17.200386\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 19.2%\n",
      "Minibatch loss at step 500: 1.715070\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 1000: 1.680272\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 1500: 0.815077\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 2000: 1.050925\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 2500: 1.091488\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 3000: 0.988056\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.0%\n",
      "Test accuracy: 85.9%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model With Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.5\n",
    "num_steps = 3001\n",
    "l2 = 0.002\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = log_reg(tf_train_dataset, weights, biases)\n",
    "  loss = tf.reduce_mean(tf.add(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels),l2*tf.nn.l2_loss(weights)))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 21.158524\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 8.7%\n",
      "Minibatch loss at step 500: 2.680648\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 1000: 1.424516\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1500: 0.787888\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2000: 0.765174\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2500: 0.798362\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 3000: 0.717879\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.6%\n",
      "Test accuracy: 88.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuronal Network Model Without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First lets define a fucntion to represent the topology of our Neuronal Network:\n",
    "#Topology: Multilayer Perceptron, 1 hidden layer with 1024 neurons and RELU activation function.\n",
    "\n",
    "def mlp(x, weights, biases,l2=0):\n",
    "    '''\n",
    "    x: tf array with the training examples\n",
    "    weights: dictionary with the tensors containing the weights for each layer\n",
    "    biases: dictionary with the tensors containing the biases for each layer\n",
    "    '''\n",
    "    if(l2==0):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "    else:\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h1']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['out']))\n",
    "    \n",
    "    #we return the values predicted by the network in the output layer\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "training_epochs = 3001\n",
    "learning_rate = 0.5\n",
    "display_step = 500\n",
    "n_hidden_1 = 1024\n",
    "n_imput = image_size * image_size\n",
    "n_classes = num_labels\n",
    "\n",
    "#Neuronal network definitio as a TF Graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #graph imputs\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = (batch_size, n_imput))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, n_classes))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    #graph variables\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([n_imput, n_hidden_1])),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_1,n_classes]))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "    \n",
    "    #Network Topology: Fully connected 1 hidden 1024 neurons, relu activation function.\n",
    "    \n",
    "    net_out = mlp(tf_train_dataset, weights, biases)\n",
    "    \n",
    "    #now we define the cost (loss) function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net_out,tf_train_labels))\n",
    "    \n",
    "    #new we define out optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    #now we define the prediction operations for training, validation and test data.\n",
    "    train_prediction = tf.nn.softmax(net_out)\n",
    "    valid_prediction = tf.nn.softmax(mlp(tf_valid_dataset,weights,biases))\n",
    "    test_prediction = tf.nn.softmax(mlp(tf_test_dataset,weights,biases))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Variables Initialized!\n",
      "Minibatch loss at step 0: 316.791687012\n",
      "Minibatch accuracy: 10.15625\n",
      "Validation accuracy: 28.94\n",
      "Minibatch loss at step 500: 17.3185119629\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 79.82\n",
      "Minibatch loss at step 1000: 15.0953474045\n",
      "Minibatch accuracy: 82.03125\n",
      "Validation accuracy: 78.84\n",
      "Minibatch loss at step 1500: 5.28393745422\n",
      "Minibatch accuracy: 82.8125\n",
      "Validation accuracy: 81.52\n",
      "Minibatch loss at step 2000: 2.11602020264\n",
      "Minibatch accuracy: 91.40625\n",
      "Validation accuracy: 80.76\n",
      "Minibatch loss at step 2500: 11.7564563751\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 79.98\n",
      "Minibatch loss at step 3000: 3.33054542542\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 81.0\n",
      "Test accuracy: 87.7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEmqGoOFJEmqGoOFJEmqmv8fo0vni0F2r6wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe768159b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#let't store the cost at each epoch in order to plot it at the end\n",
    "\n",
    "mycost = []\n",
    "epoch = []\n",
    "\n",
    "#we compute the graph now!\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    #initializing the graph variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Graph Variables Initialized!\")\n",
    "    \n",
    "    for step in range(training_epochs):\n",
    "        #calculate the offset for the mini-batch\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        #generate the mini-batch\n",
    "        batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #running the graph with the mini-batch data as the training dataset\n",
    "        dummy, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #printing partial results each display_steps times\n",
    "        if(step % display_step == 0):\n",
    "            mycost.append(l)\n",
    "            epoch.append(step)\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step,l))\n",
    "            print(\"Minibatch accuracy: {}\".format(accuracy(predictions,batch_labels)))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"Test accuracy: {}\".format(accuracy(test_prediction.eval(),test_labels)))\n",
    "    \n",
    "    plt.plot(epoch,mycost,linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronal Network Model With L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "training_epochs = 3001\n",
    "learning_rate = 0.5\n",
    "display_step = 500\n",
    "n_hidden_1 = 1024\n",
    "n_imput = image_size * image_size\n",
    "n_classes = num_labels\n",
    "l2 = 0.0001\n",
    "\n",
    "#Neuronal network definitio as a TF Graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #graph imputs\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = (batch_size, n_imput))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, n_classes))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    #graph variables\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([n_imput, n_hidden_1])),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_1,n_classes]))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "    \n",
    "    #Network Topology: Fully connected 1 hidden 1024 neurons, relu activation function.\n",
    "    \n",
    "    net_out = mlp(tf_train_dataset, weights, biases,l2)\n",
    "    \n",
    "    #now we define the cost (loss) function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net_out,tf_train_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #new we define out optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    #now we define the prediction operations for training, validation and test data.\n",
    "    train_prediction = tf.nn.softmax(net_out)\n",
    "    valid_prediction = tf.nn.softmax(mlp(tf_valid_dataset,weights,biases,l2))\n",
    "    test_prediction = tf.nn.softmax(mlp(tf_test_dataset,weights,biases,l2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Variables Initialized!\n",
      "Minibatch loss at step 0: 302.390563965\n",
      "Minibatch accuracy: 14.0625\n",
      "Validation accuracy: 23.2\n",
      "Minibatch loss at step 500: 13.2263364792\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 80.14\n",
      "Minibatch loss at step 1000: 9.59216308594\n",
      "Minibatch accuracy: 85.9375\n",
      "Validation accuracy: 80.08\n",
      "Minibatch loss at step 1500: 10.9576950073\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 76.52\n",
      "Minibatch loss at step 2000: 5.75169181824\n",
      "Minibatch accuracy: 84.375\n",
      "Validation accuracy: 82.36\n",
      "Minibatch loss at step 2500: 4.61680936813\n",
      "Minibatch accuracy: 91.40625\n",
      "Validation accuracy: 81.96\n",
      "Minibatch loss at step 3000: 3.21753931046\n",
      "Minibatch accuracy: 81.25\n",
      "Validation accuracy: 82.36\n",
      "Test accuracy: 88.68\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69eb41af50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#let't store the cost at each epoch in order to plot it at the end\n",
    "\n",
    "mycost = []\n",
    "epoch = []\n",
    "\n",
    "#we compute the graph now!\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    #initializing the graph variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Graph Variables Initialized!\")\n",
    "    \n",
    "    for step in range(training_epochs):\n",
    "        #calculate the offset for the mini-batch\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        #generate the mini-batch\n",
    "        batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #running the graph with the mini-batch data as the training dataset\n",
    "        dummy, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #printing partial results each display_steps times\n",
    "        if(step % display_step == 0):\n",
    "            mycost.append(l)\n",
    "            epoch.append(step)\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step,l))\n",
    "            print(\"Minibatch accuracy: {}\".format(accuracy(predictions,batch_labels)))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"Test accuracy: {}\".format(accuracy(test_prediction.eval(),test_labels)))\n",
    "    \n",
    "    plt.plot(epoch,mycost,linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "training_epochs = 10\n",
    "learning_rate = 0.5\n",
    "display_step = 1\n",
    "n_hidden_1 = 1024\n",
    "n_imput = image_size * image_size\n",
    "n_classes = num_labels\n",
    "l2 = 0.0001\n",
    "\n",
    "#Neuronal network definitio as a TF Graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #graph imputs\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = (batch_size, n_imput))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, n_classes))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    #graph variables\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([n_imput, n_hidden_1])),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_1,n_classes]))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "    \n",
    "    #Network Topology: Fully connected 1 hidden 1024 neurons, relu activation function.\n",
    "    \n",
    "    net_out = mlp(tf_train_dataset, weights, biases,l2)\n",
    "    \n",
    "    #now we define the cost (loss) function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net_out,tf_train_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #new we define out optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    #now we define the prediction operations for training, validation and test data.\n",
    "    train_prediction = tf.nn.softmax(net_out)\n",
    "    valid_prediction = tf.nn.softmax(mlp(tf_valid_dataset,weights,biases,l2))\n",
    "    test_prediction = tf.nn.softmax(mlp(tf_test_dataset,weights,biases,l2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Variables Initialized!\n",
      "Minibatch loss at step 0: 309.693603516\n",
      "Minibatch accuracy: 7.8125\n",
      "Validation accuracy: 21.08\n",
      "Minibatch loss at step 1: 1481.8145752\n",
      "Minibatch accuracy: 22.65625\n",
      "Validation accuracy: 45.34\n",
      "Minibatch loss at step 2: 763.462219238\n",
      "Minibatch accuracy: 60.9375\n",
      "Validation accuracy: 38.66\n",
      "Minibatch loss at step 3: 959.102722168\n",
      "Minibatch accuracy: 33.59375\n",
      "Validation accuracy: 43.4\n",
      "Minibatch loss at step 4: 958.191101074\n",
      "Minibatch accuracy: 44.53125\n",
      "Validation accuracy: 44.9\n",
      "Minibatch loss at step 5: 518.217285156\n",
      "Minibatch accuracy: 42.96875\n",
      "Validation accuracy: 55.6\n",
      "Minibatch loss at step 6: 226.894729614\n",
      "Minibatch accuracy: 55.46875\n",
      "Validation accuracy: 63.66\n",
      "Minibatch loss at step 7: 222.007843018\n",
      "Minibatch accuracy: 63.28125\n",
      "Validation accuracy: 67.46\n",
      "Minibatch loss at step 8: 258.156036377\n",
      "Minibatch accuracy: 64.84375\n",
      "Validation accuracy: 67.26\n",
      "Minibatch loss at step 9: 165.40032959\n",
      "Minibatch accuracy: 69.53125\n",
      "Validation accuracy: 73.82\n",
      "Test accuracy: 81.72\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKTt/wPv4dpdt7yaFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69eefb0250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#let't store the cost at each epoch in order to plot it at the end\n",
    "\n",
    "mycost = []\n",
    "epoch = []\n",
    "\n",
    "#we compute the graph now!\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    #initializing the graph variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Graph Variables Initialized!\")\n",
    "    \n",
    "    for step in range(training_epochs):\n",
    "        #calculate the offset for the mini-batch\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        #generate the mini-batch\n",
    "        batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #running the graph with the mini-batch data as the training dataset\n",
    "        dummy, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #printing partial results each display_steps times\n",
    "        if(step % display_step == 0):\n",
    "            mycost.append(l)\n",
    "            epoch.append(step)\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step,l))\n",
    "            print(\"Minibatch accuracy: {}\".format(accuracy(predictions,batch_labels)))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"Test accuracy: {}\".format(accuracy(test_prediction.eval(),test_labels)))\n",
    "    \n",
    "    plt.plot(epoch,mycost,linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First lets define a fucntion to represent the topology of our Neuronal Network:\n",
    "#Topology: Multilayer Perceptron, 1 hidden layer with 1024 neurons and RELU activation function.\n",
    "\n",
    "def mlp2(x, weights, biases,l2=0,drop_out=\"N\",keep_prob=1):\n",
    "    '''\n",
    "    x: tf array with the training examples\n",
    "    weights: dictionary with the tensors containing the weights for each layer\n",
    "    biases: dictionary with the tensors containing the biases for each layer\n",
    "    '''\n",
    "    if(l2==0 and drop_out==\"N\"):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "    if(l2>0 and drop_out==\"N\"):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h1']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['out']))\n",
    "    if(l2==0 and drop_out==\"Y\"):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #now we shutdown some neurons outputs and scale the rest by a factor of 1 + (1-keep_prob) = 2-keep_prob\n",
    "        h1_layer = tf.nn.dropout(h1_layer,keep_prob)*(2-keep_prob) \n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "    if(l2>0 and drop_out==\"Y\"):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #now we shutdown some neurons outputs and scale the rest by a factor of 1 + (1-keep_prob) = 2-keep_prob\n",
    "        h1_layer = tf.nn.dropout(h1_layer,keep_prob)*(2-keep_prob) \n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h1']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['out']))\n",
    "    \n",
    "    \n",
    "    #we return the values predicted by the network in the output layer\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "training_epochs = 3001\n",
    "learning_rate = 0.5\n",
    "display_step = 500\n",
    "n_hidden_1 = 1024\n",
    "n_imput = image_size * image_size\n",
    "n_classes = num_labels\n",
    "l2 = 0.0001\n",
    "keep_prob = 0.9 #this is 1 - dropout rate. So, if I want 0.2 dropout probability I use 0.8 of keep_prob\n",
    "\n",
    "#Neuronal network definitio as a TF Graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #graph imputs\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = (batch_size, n_imput))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, n_classes))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    #graph variables\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([n_imput, n_hidden_1])),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_1,n_classes]))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "    \n",
    "    #Network Topology: Fully connected 1 hidden 1024 neurons, relu activation function.\n",
    "    \n",
    "    net_out = mlp2(tf_train_dataset, weights, biases,l2,drop_out=\"Y\",keep_prob=keep_prob)\n",
    "    \n",
    "    #now we define the cost (loss) function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net_out,tf_train_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #new we define out optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    #now we define the prediction operations for training, validation and test data.\n",
    "    train_prediction = tf.nn.softmax(net_out)\n",
    "    valid_prediction = tf.nn.softmax(mlp2(tf_valid_dataset,weights,biases,l2=l2,drop_out=\"N\")) #only apply dropout during training\n",
    "    test_prediction = tf.nn.softmax(mlp2(tf_test_dataset,weights,biases,l2=l2,drop_out=\"N\")) #only apply dropout during training\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Variables Initialized!\n",
      "Minibatch loss at step 0: 376.112426758\n",
      "Minibatch accuracy: 10.15625\n",
      "Validation accuracy: 31.0\n",
      "Minibatch loss at step 500: 15.837141037\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 80.72\n",
      "Minibatch loss at step 1000: 10.9723367691\n",
      "Minibatch accuracy: 85.15625\n",
      "Validation accuracy: 80.02\n",
      "Minibatch loss at step 1500: 10.4364070892\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 77.8\n",
      "Minibatch loss at step 2000: 7.08001041412\n",
      "Minibatch accuracy: 78.90625\n",
      "Validation accuracy: 81.8\n",
      "Minibatch loss at step 2500: 5.04674243927\n",
      "Minibatch accuracy: 85.15625\n",
      "Validation accuracy: 80.72\n",
      "Minibatch loss at step 3000: 2.61497545242\n",
      "Minibatch accuracy: 81.25\n",
      "Validation accuracy: 81.6\n",
      "Test accuracy: 88.26\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYCFJkmrGYCFJkmrGYCFJkmrm/wd+YGT3F4a0gAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69eeea6f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#let't store the cost at each epoch in order to plot it at the end\n",
    "\n",
    "mycost = []\n",
    "epoch = []\n",
    "\n",
    "#we compute the graph now!\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    #initializing the graph variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Graph Variables Initialized!\")\n",
    "    \n",
    "    for step in range(training_epochs):\n",
    "        #calculate the offset for the mini-batch\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        #generate the mini-batch\n",
    "        batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #running the graph with the mini-batch data as the training dataset\n",
    "        dummy, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #printing partial results each display_steps times\n",
    "        if(step % display_step == 0):\n",
    "            mycost.append(l)\n",
    "            epoch.append(step)\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step,l))\n",
    "            print(\"Minibatch accuracy: {}\".format(accuracy(predictions,batch_labels)))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"Test accuracy: {}\".format(accuracy(test_prediction.eval(),test_labels)))\n",
    "    \n",
    "    plt.plot(epoch,mycost,linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First lets define a fucntion to represent the topology of our Neuronal Network\n",
    "\n",
    "def mlp3(x, weights, biases,l2=0,drop_out=\"N\",keep_prob=1):\n",
    "    '''\n",
    "    x: tf array with the training examples\n",
    "    weights: dictionary with the tensors containing the weights for each layer\n",
    "    biases: dictionary with the tensors containing the biases for each layer\n",
    "    '''\n",
    "    if(l2==0 and drop_out==\"N\"):\n",
    "        #h1 layer z = XW1 + b1\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        \n",
    "        #h2 layer z = h1W2 + b2\n",
    "        h2_layer = tf.add(tf.matmul(h1_layer,weights['h2']), biases['b2'])\n",
    "        #h2 layer activation function relu(z)\n",
    "        h2_layer = tf.nn.relu(h2_layer)\n",
    "        \n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h2_layer,weights['out']), biases['out'])\n",
    "        \n",
    "    if(l2>0 and drop_out==\"N\"):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        \n",
    "        #h2 layer z = h1W2 + b2\n",
    "        h2_layer = tf.add(tf.matmul(h1_layer,weights['h2']), biases['b2'])\n",
    "        #h2 layer activation function relu(z)\n",
    "        h2_layer = tf.nn.relu(h2_layer)\n",
    "        \n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h2_layer,weights['out']), biases['out'])\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h1']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h2']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['out']))\n",
    "        \n",
    "    if(l2==0 and drop_out==\"Y\"):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #now we shutdown some neurons outputs and scale the rest by a factor of 1 + (1-keep_prob) = 2-keep_prob\n",
    "        h1_layer = tf.nn.dropout(h1_layer,keep_prob)*(2-keep_prob) \n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        \n",
    "        #h2 layer z = h1W2 + b2\n",
    "        h2_layer = tf.add(tf.matmul(h1_layer,weights['h2']), biases['b2'])\n",
    "        #now we shutdown some neurons outputs and scale the rest by a factor of 1 + (1-keep_prob) = 2-keep_prob\n",
    "        h2_layer = tf.nn.dropout(h2_layer,keep_prob)*(2-keep_prob)\n",
    "        #h2 layer activation function relu(z)\n",
    "        h2_layer = tf.nn.relu(h2_layer)\n",
    "        \n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h2_layer,weights['out']), biases['out'])\n",
    "        \n",
    "    if(l2>0 and drop_out==\"Y\"):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #now we shutdown some neurons outputs and scale the rest by a factor of 1 + (1-keep_prob) = 2-keep_prob\n",
    "        h1_layer = tf.nn.dropout(h1_layer,keep_prob)*(2-keep_prob) \n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        \n",
    "        #h2 layer z = h1W2 + b2\n",
    "        h2_layer = tf.add(tf.matmul(h1_layer,weights['h2']), biases['b2'])\n",
    "        #now we shutdown some neurons outputs and scale the rest by a factor of 1 + (1-keep_prob) = 2-keep_prob\n",
    "        h2_layer = tf.nn.dropout(h2_layer,keep_prob)*(2-keep_prob)\n",
    "        #h2 layer activation function relu(z)\n",
    "        h2_layer = tf.nn.relu(h2_layer)\n",
    "        \n",
    "        \n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h2_layer,weights['out']), biases['out'])\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h1']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h2']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['out']))\n",
    "    \n",
    "    \n",
    "    #we return the values predicted by the network in the output layer\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "training_epochs = 3001\n",
    "learning_rate = 0.5\n",
    "display_step = 500\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 512\n",
    "n_imput = image_size * image_size\n",
    "n_classes = num_labels\n",
    "l2 = 0.0001\n",
    "keep_prob = 0.9 #this is 1 - dropout rate. So, if I want 0.2 dropout probability I use 0.8 of keep_prob\n",
    "\n",
    "#Neuronal network definitio as a TF Graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #graph imputs\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = (batch_size, n_imput))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, n_classes))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    #graph variables\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([n_imput, n_hidden_1])),\n",
    "        'h2': tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_2,n_classes]))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "    \n",
    "    #Network Topology: Fully connected 1 hidden 1024 neurons, relu activation function.\n",
    "    \n",
    "    #net_out = mlp3(tf_train_dataset, weights, biases,l2,drop_out=\"Y\",keep_prob=keep_prob)\n",
    "    net_out = mlp3(tf_train_dataset, weights, biases,l2=0,drop_out=\"N\",keep_prob=1)\n",
    "    \n",
    "    #now we define the cost (loss) function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net_out,tf_train_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #new we define out optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    #now we define the prediction operations for training, validation and test data.\n",
    "    train_prediction = tf.nn.softmax(net_out)\n",
    "    #valid_prediction = tf.nn.softmax(mlp3(tf_valid_dataset,weights,biases,l2=l2,drop_out=\"N\")) #only apply dropout during training\n",
    "    valid_prediction = tf.nn.softmax(mlp3(tf_valid_dataset,weights,biases,l2=0,drop_out=\"N\"))\n",
    "    #test_prediction = tf.nn.softmax(mlp3(tf_test_dataset,weights,biases,l2=l2,drop_out=\"N\")) #only apply dropout during training\n",
    "    test_prediction = tf.nn.softmax(mlp3(tf_test_dataset,weights,biases,l2=0,drop_out=\"N\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Variables Initialized!\n",
      "Minibatch loss at step 0: 5098.31396484\n",
      "Minibatch accuracy: 7.03125\n",
      "Validation accuracy: 10.0\n",
      "Minibatch loss at step 500: nan\n",
      "Minibatch accuracy: 10.15625\n",
      "Validation accuracy: 10.0\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 10.9375\n",
      "Validation accuracy: 10.0\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 9.375\n",
      "Validation accuracy: 10.0\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 12.5\n",
      "Validation accuracy: 10.0\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 9.375\n",
      "Validation accuracy: 10.0\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 8.59375\n",
      "Validation accuracy: 10.0\n",
      "Test accuracy: 10.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAFkCAYAAACEpYlzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69e89cae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#let't store the cost at each epoch in order to plot it at the end\n",
    "\n",
    "mycost = []\n",
    "epoch = []\n",
    "\n",
    "#we compute the graph now!\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    #initializing the graph variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Graph Variables Initialized!\")\n",
    "    \n",
    "    for step in range(training_epochs):\n",
    "        #calculate the offset for the mini-batch\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        #generate the mini-batch\n",
    "        batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #running the graph with the mini-batch data as the training dataset\n",
    "        dummy, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #printing partial results each display_steps times\n",
    "        if(step % display_step == 0):\n",
    "            mycost.append(l)\n",
    "            epoch.append(step)\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step,l))\n",
    "            print(\"Minibatch accuracy: {}\".format(accuracy(predictions,batch_labels)))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"Test accuracy: {}\".format(accuracy(test_prediction.eval(),test_labels)))\n",
    "    \n",
    "    plt.plot(epoch,mycost,linewidth=2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
