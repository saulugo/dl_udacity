{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "# Techtalk Synergic Partners - 23 Feb 2017\n",
    "\n",
    "## Sa√∫l Lugo\n",
    "\n",
    "#### This notebook has been adapted from an assigment in the Introductory course to Deep Learning at www.udacity.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (100000, 28, 28) (100000,)\n",
      "Validation set (5000, 28, 28) (5000,)\n",
      "Test set (5000, 28, 28) (5000,)\n",
      "Final Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  final_test_dataset = save['final_test_dataset']\n",
    "  final_test_labels = save['final_test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)\n",
    "  print('Final Test set', final_test_dataset.shape, final_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (100000, 784) (100000, 10)\n",
      "Validation set (5000, 784) (5000, 10)\n",
      "Test set (5000, 784) (5000, 10)\n",
      "Final Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "final_test_dataset, final_test_labels = reformat(final_test_dataset, final_test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "print('Final Test set', final_test_dataset.shape,final_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronal Network Model With L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First lets define a fucntion to represent the topology of our Neuronal Network:\n",
    "#Topology: Multilayer Perceptron, 1 hidden layer with 1024 neurons and RELU activation function.\n",
    "\n",
    "def mlp(x, weights, biases,l2=0):\n",
    "    '''\n",
    "    x: tf array with the training examples\n",
    "    weights: dictionary with the tensors containing the weights for each layer\n",
    "    biases: dictionary with the tensors containing the biases for each layer\n",
    "    '''\n",
    "    if(l2==0):\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "    else:\n",
    "        #h1 layer z = XW + b\n",
    "        h1_layer = tf.add(tf.matmul(x,weights['h1']), biases['b1'])\n",
    "        #h1 layer activation function relu(z)\n",
    "        h1_layer = tf.nn.relu(h1_layer)\n",
    "        #output layer (no activation needed after output layer)\n",
    "        out_layer = tf.add(tf.matmul(h1_layer,weights['out']), biases['out'])\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['h1']))\n",
    "        out_layer = tf.add(out_layer,l2*tf.nn.l2_loss(weights['out']))\n",
    "    \n",
    "    #we return the values predicted by the network in the output layer\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hyper-parameters\n",
    "\n",
    "batch_size = 128\n",
    "training_epochs = 3001\n",
    "learning_rate = 0.5\n",
    "display_step = 500\n",
    "n_hidden_1 = 1024\n",
    "n_imput = image_size * image_size\n",
    "n_classes = num_labels\n",
    "l2 = 0.0001\n",
    "\n",
    "#Neuronal network definitio as a TF Graph\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    #graph imputs\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape = (batch_size, n_imput))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, n_classes))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    #graph variables\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.truncated_normal([n_imput, n_hidden_1])),\n",
    "        'out': tf.Variable(tf.truncated_normal([n_hidden_1,n_classes]))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
    "        'out': tf.Variable(tf.zeros([n_classes]))\n",
    "    }\n",
    "    \n",
    "    #Network Topology: Fully connected 1 hidden 1024 neurons, relu activation function.\n",
    "    \n",
    "    net_out = mlp(tf_train_dataset, weights, biases,l2)\n",
    "    \n",
    "    #now we define the cost (loss) function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(net_out,tf_train_labels))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #new we define out optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    #now we define the prediction operations for training, validation and test data.\n",
    "    train_prediction = tf.nn.softmax(net_out)\n",
    "    valid_prediction = tf.nn.softmax(mlp(tf_valid_dataset,weights,biases,l2))\n",
    "    test_prediction = tf.nn.softmax(mlp(tf_test_dataset,weights,biases,l2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Variables Initialized!\n",
      "Minibatch loss at step 0: 411.915039062\n",
      "Minibatch accuracy: 7.03125\n",
      "Validation accuracy: 24.24\n",
      "Minibatch loss at step 500: 15.6833934784\n",
      "Minibatch accuracy: 80.46875\n",
      "Validation accuracy: 80.9\n",
      "Minibatch loss at step 1000: 10.4664525986\n",
      "Minibatch accuracy: 82.8125\n",
      "Validation accuracy: 81.12\n",
      "Minibatch loss at step 1500: 13.6425762177\n",
      "Minibatch accuracy: 85.15625\n",
      "Validation accuracy: 80.2\n",
      "Minibatch loss at step 2000: 6.61259174347\n",
      "Minibatch accuracy: 84.375\n",
      "Validation accuracy: 82.28\n",
      "Minibatch loss at step 2500: 5.10856151581\n",
      "Minibatch accuracy: 89.0625\n",
      "Validation accuracy: 81.94\n",
      "Minibatch loss at step 3000: 1.25070548058\n",
      "Minibatch accuracy: 85.9375\n",
      "Validation accuracy: 82.48\n",
      "Test accuracy: 88.94\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVLDGCwkSVLD/P8Czt6tp3RcZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36c2890950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#let't store the cost at each epoch in order to plot it at the end\n",
    "\n",
    "mycost = []\n",
    "epoch = []\n",
    "\n",
    "#we compute the graph now!\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    #initializing the graph variables\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Graph Variables Initialized!\")\n",
    "    \n",
    "    for step in range(training_epochs):\n",
    "        #calculate the offset for the mini-batch\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        \n",
    "        #generate the mini-batch\n",
    "        batch_data = train_dataset[offset:(offset+batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset+batch_size), :]\n",
    "        \n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        #running the graph with the mini-batch data as the training dataset\n",
    "        dummy, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #printing partial results each display_steps times\n",
    "        if(step % display_step == 0):\n",
    "            mycost.append(l)\n",
    "            epoch.append(step)\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step,l))\n",
    "            print(\"Minibatch accuracy: {}\".format(accuracy(predictions,batch_labels)))\n",
    "            print(\"Validation accuracy: {}\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"Test accuracy: {}\".format(accuracy(test_prediction.eval(),test_labels)))\n",
    "    \n",
    "    plt.plot(epoch,mycost,linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Proposed Exercise\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
